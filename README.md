Toxic Comment Classifier project:

Dataset Link:
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data

Objective:
Build a multi-headed model capable of detecting and assigning probabilities for different types of of toxicity such as:

toxic
severe toxic
obscene
threat
insult
identity hate

The dataset comprises of comments from Wikipedia's talk page (ie. discussion) pages.


-->Cyberbullying is a major societal problem that can lead to teen suicides

-->Toxic comment classifier helps to filter out toxic words to make online
world a safer and more harmonious place.

Techonlogies used:

--> More advanced Python users who have some knowledge of ML
algorithms (e.g. random forest), NLP and Flask

Download the following dependencies to your conda environment before proceeding:

dependencies:
  - ipykernel
  - ipython
  - ipython_genutils
  - jupyter_client
  - jupyter_core
  - jupyter
  - line_profiler
  - matplotlib
  - memory_profiler
  - nltk
  - numpy>=1.16
  - pandas>=0.24.0
  - psutil
  - python>=3.6
  - scikit-learn>=0.20
  - scipy
  - seaborn
  - setuptools

  To run the app:

  Make a clone of the project into a convenient location on your pc


-->Open Anaconda Prompt/terminal for mac or linux

-->Change directory to 'Flask app' using cd command

-->Enter 'python toxic.py' to run the Python file(make sure you have flask installed)

-->Copy the IP address Running on http://127.0.0.1:5000/ into your browser

--->You should see the app running.

